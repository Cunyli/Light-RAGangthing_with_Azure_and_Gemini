#!/usr/bin/env python3
"""
Debug Azure OpenAI configuration - æ¨¡æ‹ŸRAGAnythingçš„å®é™…ä½¿ç”¨æ–¹å¼
"""

import asyncio
import os
from dotenv import load_dotenv
from openai import AsyncAzureOpenAI
import aiohttp

# Load environment variables
load_dotenv()

async def test_direct_url_request():
    """ç›´æ¥ä½¿ç”¨å®Œæ•´URLæµ‹è¯•ï¼ˆæ¨¡æ‹ŸRAGAnythingçš„æ–¹å¼ï¼‰"""
    
    print("=== æµ‹è¯•1: ç›´æ¥ä½¿ç”¨å®Œæ•´URL (æ¨¡æ‹ŸRAGAnythingæ–¹å¼) ===")
    
    # ä½¿ç”¨RAGAnythingçš„é…ç½®æ–¹å¼
    full_embedding_url = os.getenv("EMBEDDING_BINDING_HOST")
    api_key = os.getenv("EMBEDDING_BINDING_API_KEY")
    
    print(f"å®Œæ•´URL: {full_embedding_url}")
    print(f"API Key: {'*' * 60 + api_key[-4:] if api_key else 'None'}")
    
    headers = {
        "Content-Type": "application/json",
        "api-key": api_key
    }
    
    payload = {
        "input": ["This is a test sentence for embedding."],
        "model": "text-embedding-3-small"
    }
    
    try:
        async with aiohttp.ClientSession() as session:
            print("å‘é€ç›´æ¥HTTPè¯·æ±‚...")
            async with session.post(full_embedding_url, json=payload, headers=headers) as response:
                print(f"çŠ¶æ€ç : {response.status}")
                print(f"å“åº”å¤´: {dict(response.headers)}")
                
                if response.status == 200:
                    result = await response.json()
                    print("âœ… ç›´æ¥URLè¯·æ±‚æˆåŠŸ!")
                    print(f"   åµŒå…¥ç»´åº¦: {len(result['data'][0]['embedding'])}")
                    return True
                else:
                    error_text = await response.text()
                    print(f"âŒ ç›´æ¥URLè¯·æ±‚å¤±è´¥!")
                    print(f"   é”™è¯¯å†…å®¹: {error_text}")
                    return False
    except Exception as e:
        print(f"âŒ è¯·æ±‚å¼‚å¸¸: {str(e)}")
        return False

async def test_azure_client_method():
    """ä½¿ç”¨Azure OpenAIå®¢æˆ·ç«¯æµ‹è¯•ï¼ˆæˆ‘ä»¬ä¹‹å‰æˆåŠŸçš„æ–¹å¼ï¼‰"""
    
    print("\n=== æµ‹è¯•2: Azure OpenAIå®¢æˆ·ç«¯æ–¹å¼ ===")
    
    api_key = os.getenv("EMBEDDING_BINDING_API_KEY")
    binding_host = os.getenv("EMBEDDING_BINDING_HOST")
    deployment = os.getenv("AZURE_EMBEDDING_DEPLOYMENT")
    api_version = os.getenv("AZURE_EMBEDDING_API_VERSION")
    
    # ä»å®Œæ•´URLæå–endpoint
    endpoint = "/".join(binding_host.split("/")[:3])
    
    try:
        client = AsyncAzureOpenAI(
            api_key=api_key,
            azure_endpoint=endpoint,
            api_version=api_version
        )
        
        print("ä½¿ç”¨Azure OpenAIå®¢æˆ·ç«¯å‘é€è¯·æ±‚...")
        response = await client.embeddings.create(
            input="This is a test sentence for embedding.",
            model=deployment
        )
        
        print("âœ… Azureå®¢æˆ·ç«¯è¯·æ±‚æˆåŠŸ!")
        print(f"   åµŒå…¥ç»´åº¦: {len(response.data[0].embedding)}")
        return True
        
    except Exception as e:
        print(f"âŒ Azureå®¢æˆ·ç«¯è¯·æ±‚å¤±è´¥: {str(e)}")
        return False

async def test_llm_request():
    """æµ‹è¯•LLMè¯·æ±‚"""
    
    print("\n=== æµ‹è¯•3: LLMè¯·æ±‚æµ‹è¯• ===")
    
    api_key = os.getenv("LLM_BINDING_API_KEY")
    full_llm_url = os.getenv("LLM_BINDING_HOST")
    
    print(f"LLM URL: {full_llm_url}")
    
    headers = {
        "Content-Type": "application/json",
        "api-key": api_key
    }
    
    payload = {
        "messages": [{"role": "user", "content": "Say 'Hello World'"}],
        "model": "gpt-4o-mini",
        "max_tokens": 50
    }
    
    try:
        async with aiohttp.ClientSession() as session:
            print("å‘é€LLMè¯·æ±‚...")
            async with session.post(full_llm_url, json=payload, headers=headers) as response:
                print(f"çŠ¶æ€ç : {response.status}")
                
                if response.status == 200:
                    result = await response.json()
                    print("âœ… LLMè¯·æ±‚æˆåŠŸ!")
                    print(f"   å“åº”: {result['choices'][0]['message']['content']}")
                    return True
                else:
                    error_text = await response.text()
                    print(f"âŒ LLMè¯·æ±‚å¤±è´¥!")
                    print(f"   é”™è¯¯å†…å®¹: {error_text}")
                    return False
    except Exception as e:
        print(f"âŒ LLMè¯·æ±‚å¼‚å¸¸: {str(e)}")
        return False

async def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("å¼€å§‹è°ƒè¯•Azure OpenAIé…ç½®...")
    print("=" * 50)
    
    # æµ‹è¯•1: ç›´æ¥URLæ–¹å¼ï¼ˆRAGAnythingä½¿ç”¨çš„æ–¹å¼ï¼‰
    test1_result = await test_direct_url_request()
    
    # æµ‹è¯•2: Azureå®¢æˆ·ç«¯æ–¹å¼ï¼ˆæˆ‘ä»¬ä¹‹å‰æˆåŠŸçš„æ–¹å¼ï¼‰
    test2_result = await test_azure_client_method()
    
    # æµ‹è¯•3: LLMè¯·æ±‚
    test3_result = await test_llm_request()
    
    print("\n" + "=" * 50)
    print("æµ‹è¯•ç»“æœæ€»ç»“:")
    print(f"   ç›´æ¥URLåµŒå…¥è¯·æ±‚: {'âœ… æˆåŠŸ' if test1_result else 'âŒ å¤±è´¥'}")
    print(f"   Azureå®¢æˆ·ç«¯åµŒå…¥: {'âœ… æˆåŠŸ' if test2_result else 'âŒ å¤±è´¥'}")
    print(f"   LLMè¯·æ±‚: {'âœ… æˆåŠŸ' if test3_result else 'âŒ å¤±è´¥'}")
    
    if test1_result and test2_result and test3_result:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•éƒ½æˆåŠŸï¼é…ç½®åº”è¯¥æ²¡é—®é¢˜ã€‚")
    else:
        print("\nâš ï¸  æœ‰æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥è°ƒæŸ¥ã€‚")

if __name__ == "__main__":
    asyncio.run(main())